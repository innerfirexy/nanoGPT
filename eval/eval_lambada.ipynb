{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "lm_eval --model hf \\ \n",
    "    --model_args pretrained=gpt2 \\\n",
    "    --task lambada_standard \\ \n",
    "    --device cuda:0 \\ \n",
    "    --batch_size 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hf (pretrained=gpt2), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
    "|     Tasks      |Version|Filter|n-shot|  Metric  |   | Value |   |Stderr|\n",
    "|----------------|------:|------|-----:|----------|---|------:|---|-----:|\n",
    "|lambada_standard|      1|none  |     0|acc       |↑  | 0.2597|±  |0.0061|\n",
    "|                |       |none  |     0|perplexity|↓  |93.7302|±  |3.8329|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hf (pretrained=gpt2-medium), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
    "|     Tasks      |Version|Filter|n-shot|  Metric  |   | Value |   |Stderr|\n",
    "|----------------|------:|------|-----:|----------|---|------:|---|-----:|\n",
    "|lambada_standard|      1|none  |     0|acc       |↑  | 0.3769|±  |0.0068|\n",
    "|                |       |none  |     0|perplexity|↓  |29.6928|±  |1.0742|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hf (pretrained=gpt2-large), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
    "|     Tasks      |Version|Filter|n-shot|  Metric  |   | Value |   |Stderr|\n",
    "|----------------|------:|------|-----:|----------|---|------:|---|-----:|\n",
    "|lambada_standard|      1|none  |     0|acc       |↑  | 0.4040|±  |0.0068|\n",
    "|                |       |none  |     0|perplexity|↓  |22.1789|±  |0.7740|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hf (pretrained=gpt2-xl), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
    "|     Tasks      |Version|Filter|n-shot|  Metric  |   | Value |   |Stderr|\n",
    "|----------------|------:|------|-----:|----------|---|------:|---|-----:|\n",
    "|lambada_standard|      1|none  |     0|acc       |↑  | 0.4461|±  |0.0069|\n",
    "|                |       |none  |     0|perplexity|↓  |16.9945|±  |0.5839|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "lm_eval --model hf \\ \n",
    "    lm_eval --model hf \\--model_args pretrained=innerfirexy/gpt2-cepred \\\n",
    "    --task lambada_standard \\ \n",
    "    --device cuda:0 \\ \n",
    "    --batch_size 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hf (pretrained=innerfirexy/gpt2-cepred), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
    "|     Tasks      |Version|Filter|n-shot|  Metric  |   | Value |   |Stderr|\n",
    "|----------------|------:|------|-----:|----------|---|------:|---|-----:|\n",
    "|lambada_standard|      1|none  |     0|acc       |↑  | 0.2614|±  |0.0061|\n",
    "|                |       |none  |     0|perplexity|↓  |96.4529|±  |4.2001|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# The Winograd Schema Challenge\n",
    "# https://github.com/EleutherAI/lm-evaluation-harness/blob/main/lm_eval/tasks/wsc273/README.md\n",
    "\n",
    "lm_eval --model hf --model_args pretrained=gpt2 --task wsc273 --device cuda:0 --batch_size 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hf (pretrained=gpt2,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
    "|Tasks |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
    "|------|------:|------|-----:|------|---|-----:|---|-----:|\n",
    "|wsc273|      1|none  |     0|acc   |↑  |0.5861|±  |0.0299|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hf (pretrained=innerfirexy/gpt2-cepred,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
    "|Tasks |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
    "|------|------:|------|-----:|------|---|-----:|---|-----:|\n",
    "|wsc273|      1|none  |     0|acc   |↑  |0.5275|±  |0.0303|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# CoQA\n",
    "# https://github.com/EleutherAI/lm-evaluation-harness/tree/main/lm_eval/tasks/coqa\n",
    "\n",
    "lm_eval --model hf --model_args pretrained=gpt2 --task coqa --device cuda:0 --batch_size 8"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
